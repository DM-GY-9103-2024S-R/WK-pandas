{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 06\n",
        "\n",
        "## Some Pandas data exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024S-R/9103-utils/raw/main/src/io_utils.py\n",
        "!wget -q https://github.com/DM-GY-9103-2024S-R/9103-utils/raw/main/src/data_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from data_utils import MinMaxScaler\n",
        "from io_utils import object_from_json_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKGt8bzScNA"
      },
      "source": [
        "### Dataset Exploration\n",
        "\n",
        "Let's revisit the house dataset from last homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L66UbgCWGDjF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the location of the json file here\n",
        "HOUSES_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024S-R/9103-utils/main/datasets/json/LA_housing.json\"\n",
        "\n",
        "houses_info = object_from_json_url(HOUSES_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeWkaI_lYzIE"
      },
      "source": [
        "#### Some \"light\" exploration:\n",
        "\n",
        "Ok. We should now have a list of objects with information about houses in LA.\n",
        "\n",
        "Let's work with the data to answer the following questions:\n",
        "- How many houses are in this dataset?\n",
        "- How many \"features\" does our dataset have?\n",
        "- What's the min, max and average price for the houses in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How many houses are in the dataset?\n",
        "num_houses = len(houses_info)\n",
        "\n",
        "# Features:\n",
        "house_features = houses_info[0].keys()\n",
        "\n",
        "houses_info[0], num_houses, house_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37h20s-9ZLY_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# List of prices\n",
        "\n",
        "house_prices = []\n",
        "for h in houses_info:\n",
        "  house_prices.append(h[\"value\"])\n",
        "\n",
        "# min price\n",
        "min_price = min(house_prices)\n",
        "\n",
        "# max price\n",
        "max_price = max(house_prices)\n",
        "\n",
        "# avg price\n",
        "avg_price = sum(house_prices) // num_houses\n",
        "\n",
        "min_price, max_price, avg_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### More exploring\n",
        "\n",
        "What if we wanted to get min, max and average values for all of the features?\n",
        "\n",
        "# ðŸ˜–\n",
        "\n",
        "Repeating the code above, can get annoying really quick, but hopefully we can use the `Pandas` library to help.\n",
        "\n",
        "Once we load our data into a `DataFrame` we can perform many types of calculations.\n",
        "\n",
        "Here's how we load our data into a `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df = pd.DataFrame.from_records(houses_info)\n",
        "\n",
        "# And to check the first couple of frames\n",
        "houses_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have access to each feature by simply indexing the `DataFrame` by the feature's name.\n",
        "\n",
        "For example, to get a list of all of the prices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_prices = houses_df[\"value\"]\n",
        "\n",
        "# only print first 5\n",
        "house_prices.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or a list of all of the ages of the houses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_ages = houses_df[\"age\"]\n",
        "\n",
        "# only print first 5\n",
        "house_ages.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or, we can get a sub-section of our original data with only the age and value features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_ages_values = houses_df[[\"age\", \"value\"]]\n",
        "\n",
        "# only print first 5\n",
        "house_ages_values.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Doing some maths\n",
        "\n",
        "To get the smallest value of a feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_price = houses_df[\"value\"].min()\n",
        "min_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the average (or, mean) value for a feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_price = houses_df[\"value\"].mean()\n",
        "avg_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This gives us a list with the names of the features/columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_features = list(houses_df.columns)\n",
        "house_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's similar to when we did `houses_info[0].keys()` above.\n",
        "\n",
        "Either way, we can now iterate over a list of the feature names to calculate min, max and average for each feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "for f in house_features:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", houses_df[f].min())\n",
        "  print(\"\\tmax:\", houses_df[f].max())\n",
        "  print(\"\\tavg:\", houses_df[f].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can even ask for the min (or max, or avg) of the whole `DataFrame` and it knows to do it for each column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Average / Mean\n",
        "\n",
        "The average, or mean, value of a set of numbers is a quantity that represents the center of a collection of numbers. What this means is that we expect about half of the numbers in a collection to be higher than the mean, and the other half to be lower.\n",
        "\n",
        "The mean of a set of numbers $x_1, x_2, ..., x_n$ is calculated by dividing the sum of the values by the number of values. It's sometimes written like this:\n",
        "\n",
        "$\\displaystyle \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
        "\n",
        "which is the same as `sum(X) / len(X)` in Python if `X` is our list of values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standard Deviation\n",
        "\n",
        "In addition to the mean, the standard deviation is a measure of the amount of variation in a sequence of numbers.\n",
        "\n",
        "It's calculated by taking the square root of the average of the squared differences from the mean of the sequence.\n",
        "\n",
        "In other words, first we calculate the difference between each point and the mean, and square this difference, then sum all of them up, divide by the number of values in the sequence, and finally take the square root:\n",
        "\n",
        "$\\displaystyle \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(x_{i} - \\mu \\right)^{2}}$\n",
        "\n",
        "The standard deviation is a measurement of how close all of the points are to the mean.\n",
        "\n",
        "<img src=\"./imgs/std-dev.jpg\" width=\"700px\"/>\n",
        "\n",
        "Unfortunately, there is no short Python code for computing the standard deviation like there is for the average, but the `DataFrame` object has a function for computing it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mean and standard deviation for each feature\n",
        "for f in houses_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tavg:\", houses_df[f].mean())\n",
        "  print(\"\\tstd:\", houses_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there's greater variability in the number of rooms of a house when compared to the number of bedrooms, but besides that, this isn't very useful yet because we can't really compare the standard deviations from different features that have different units.\n",
        "\n",
        "We'll see soon how we can use mean and standard deviation to be able to compare, combine, extrapolate values that were measured in different units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation\n",
        "\n",
        "Let's say we want to figure out if there are any features that correlate strongly with the house prices.\n",
        "\n",
        "This means figuring out if there are any other features that are a good indication for the value of a house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We only have a handful of features, so we can always plot them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A lot easier with Pandas DataFrames\n",
        "\n",
        "for f in house_features:\n",
        "  if f != \"value\":\n",
        "    plt.scatter(houses_df[f], houses_df[\"value\"], alpha=.1)\n",
        "    plt.xlabel(f)\n",
        "    plt.ylabel(\"value\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Covariance Matrix\n",
        "\n",
        "Instead of looking at the plots there's actually a mathematical way of calculating how much the features of a dataset are \"related\".\n",
        "\n",
        "It's called the [covariance](https://en.wikipedia.org/wiki/Covariance), and it measures how much $2$ features change together.\n",
        "\n",
        "And with our `DataFrame` we can just call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.cov()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows us how much each variable is related to every other variable, which will be useful when we start training models and want to reduce the amount of data we need to process, but for now we can just look at the covariances for the `value` feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.cov()[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the covariances with the largest magnitudes, we can see that:\n",
        "- value correlates with the number of rooms: the more rooms, the higher the price of a house.\n",
        "- value correlates inversely with age: the older the house, the less valuable it is.\n",
        "- value correlates somewhat with longitude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standardizing Values\n",
        "\n",
        "The above calculation gives us some extra information about the data, but there's a problem:\n",
        "\n",
        "All of the features are in different units. The range of the rooms feature is between $1$ and $17$, while the range of age is $2$ to $55$, and latitude and longitude vary by at most $1$ degree.\n",
        "\n",
        "Using different units to calculate the covariance can exaggerate how much certain features actually influence each other.\n",
        "\n",
        "In order to calculate covariance correctly we have to normalize the data in all columns to be \"unitless\".\n",
        "\n",
        "One way to do this is to scale each value to be within the range [0, 1] relative to the min and max values of their column.\n",
        "\n",
        "This is called [MinMax Normalization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), and we're going to use a library that will do this for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale all the values to be between 0, 1\n",
        "\n",
        "# This creates a scaler object we can use\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# This is how we use the object on our data\n",
        "houses_df_min_max = min_max_scaler.fit_transform(houses_df)\n",
        "\n",
        "# Scaled version of DataFrame\n",
        "houses_df_min_max.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can finally correctly calculate the covariances\n",
        "houses_df_min_max.cov()[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that if we scale our features according to the min and max value of each column, longitude is the top feature that correlate with value, followed by number of rooms and then age.\n",
        "\n",
        "Normalizing is an important step when working with data. This is not only true for calculating covariances, but is even more important when training models with multiple features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One more dataset\n",
        "\n",
        "Let's load..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the location of the json file here\n",
        "DIAMONDS_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024S-R/9103-utils/main/datasets/json/diamonds.json\"\n",
        "\n",
        "# Read into Python object\n",
        "diamonds_info = object_from_json_url(DIAMONDS_FILE)\n",
        "\n",
        "# Create DataFrame\n",
        "diamonds_df = pd.DataFrame.from_records(diamonds_info)\n",
        "\n",
        "diamonds_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in diamonds_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", diamonds_df[f].min())\n",
        "  print(\"\\tmax:\", diamonds_df[f].max())\n",
        "  print(\"\\tavg:\", diamonds_df[f].mean())\n",
        "  print(\"\\tstd:\", diamonds_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ˜«\n",
        "\n",
        "Some of the features aren't numerical, they're words/tags that describe some property of the diamond.\n",
        "\n",
        "We can still do some analysis. The easiest way is to just drop those columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamonds_numerical_df = diamonds_df.drop(columns=[\"cut\", \"color\", \"clarity\"])\n",
        "diamonds_numerical_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now we can get some statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in diamonds_numerical_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", diamonds_numerical_df[f].min())\n",
        "  print(\"\\tmax:\", diamonds_numerical_df[f].max())\n",
        "  print(\"\\tavg:\", diamonds_numerical_df[f].mean())\n",
        "  print(\"\\tstd:\", diamonds_numerical_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¤·\n",
        "\n",
        "Which is fine if all we're doing is taking a look at our data, but once we start training models and doing more detailed analyses we'll want to use all of the data that we have available.\n",
        "\n",
        "Let's see how to work with non-numerical properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Encoding\n",
        "\n",
        "If we look at the [dataset info](https://www.kaggle.com/datasets/shivam2503/diamonds), we'll see that those features have an order:\n",
        "\n",
        "<img src=\"./imgs/diamonds.jpg\" width=\"700px\"/>\n",
        "\n",
        "They all have a \"worse\" and a \"best\" option.\n",
        "\n",
        "This means we can assign numbers to them and include them back into our dataset analysis and eventually use them for training models.\n",
        "\n",
        "In order to do this we'll use an object called [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) from the same library that we used for doing normalization.\n",
        "\n",
        "First we have to determine all the possible values of each of these features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in [\"cut\", \"color\", \"clarity\"]:\n",
        "  print(diamonds_df[f].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then re-order them from worst to best:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
        "color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
        "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamond_encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And apply it to our `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode the columns\n",
        "ccc_vals = diamond_encoder.fit_transform(diamonds_df[[\"cut\", \"color\", \"clarity\"]].values)\n",
        "\n",
        "# Put the values back in the original DataFrame\n",
        "diamonds_df[[\"cut\", \"color\", \"clarity\"]] = ccc_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can rerun our loop to get statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in diamonds_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", diamonds_df[f].min())\n",
        "  print(\"\\tmax:\", diamonds_df[f].max())\n",
        "  print(\"\\tavg:\", diamonds_df[f].mean())\n",
        "  print(\"\\tstd:\", diamonds_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalize the data, get covariances and plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale all the values to be between 0, 1\n",
        "\n",
        "# This creates a scaler object we can use\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# This is how we use the object on our data\n",
        "diamonds_df_min_max = min_max_scaler.fit_transform(diamonds_df)\n",
        "\n",
        "# Scaled version of DataFrame\n",
        "diamonds_df_min_max.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamonds_df_min_max.cov()[\"price\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the original data\n",
        "for f in diamonds_df.columns:\n",
        "  if f != \"price\":\n",
        "    plt.scatter(diamonds_df[f], diamonds_df[\"price\"], alpha=.1)\n",
        "    plt.xlabel(f)\n",
        "    plt.ylabel(\"price\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next time: Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from data_utils import MinMaxScaler\n",
        "from io_utils import object_from_json_url\n",
        "\n",
        "# Load Dataset\n",
        "DIAMONDS_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024S-R/9103-utils/main/datasets/json/diamonds.json\"\n",
        "\n",
        "# Read into DataFrame\n",
        "diamonds_info = object_from_json_url(DIAMONDS_FILE)\n",
        "diamonds_df = pd.DataFrame.from_records(diamonds_info)\n",
        "\n",
        "\n",
        "# Encode\n",
        "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
        "color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
        "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
        "\n",
        "diamond_encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order])\n",
        "\n",
        "ccc_vals = diamond_encoder.fit_transform(diamonds_df[[\"cut\", \"color\", \"clarity\"]].values)\n",
        "diamonds_df[[\"cut\", \"color\", \"clarity\"]] = ccc_vals\n",
        "\n",
        "\n",
        "# Normalize\n",
        "diamond_scaler = MinMaxScaler()\n",
        "\n",
        "# This is how we use the object on our data\n",
        "diamonds_scaled_df = diamond_scaler.fit_transform(diamonds_df)\n",
        "\n",
        "\n",
        "# Linear Regression\n",
        "price_model = LinearRegression()\n",
        "\n",
        "# Drop price and fit the model to predict price\n",
        "no_price_df = diamonds_scaled_df.drop(columns=[\"price\"])\n",
        "price_model.fit(no_price_df.values, diamonds_scaled_df[\"price\"].values)\n",
        "\n",
        "# Run the model on the training data\n",
        "predict_price = price_model.predict(no_price_df.values)\n",
        "\n",
        "# Put price predictions back on DataFrame\n",
        "predicted_scaled_df = no_price_df.assign(price=predict_price)\n",
        "\n",
        "# Un-normalize the data\n",
        "predicted_df = diamond_scaler.inverse_transform(predicted_scaled_df)\n",
        "\n",
        "# Measure error\n",
        "mean_squared_error(diamonds_df[\"price\"].values, predicted_df[\"price\"].values, squared=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
